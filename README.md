#Facial Awareness

For my openFrameworks final I created a virtual ball interaction for users to play in order to evoke feelings of an augmented reality as well as an understanding of the intertwinement of the natural and the artificial. 

I used the ofxOpenCv add-on for this project in order to detect faces. The openCV add-on allows the interaction to be more accessible to users because it only requires the use of a laptop and its camera. 

The next step for this project would be to use either the blob tracker add-on or facial tracker to create a more accurate interaction with the balls in the screen. I think I would also like to learn how to use Box2D in the future to incorporate physics into the project. I had issues trying to mesh openCV with Box2D, but I would like to experiment further.

[Video: FIRST ATTEMPT](https://vimeo.com/146846950)

[Video: SECOND TRY (USING Box2D)](https://www.youtube.com/watch?v=fTIsT60ROYo&feature=youtu.be)

[Video: THIRD TRY](https://youtu.be/W1yZQAnm_hQ) This attempt was able to detect the collision and print to the console, but for some reason it only affected one of the balls and not in the way I would have liked. 

[Video: FOURTH TRY]() I started over for roughly the fourth attempt and it was the closest I could get to the interaction. Something is still not quite right. Check out the [code](https://github.com/jmitch12/thirdAttempt).

![Alt text](https://github.com/jmitch12/openFrameworksFinal/blob/master/face.png "Face")

I used a few online sources for this project, but my classmates were most helpful.

###Sources

[ofxOpenCv](http://openframeworks.cc/documentation/ofxOpenCv/introduction.html)

ClassCode Example for OpenCV add-on

[Box2D](http://box2d.org/)

Andrew Genualdi

Umi Syam 

Saman Tehrani

###FINAL PROJECT TWO

[Link to Repository](https://github.com/jmitch12/ofFinalTwo)
